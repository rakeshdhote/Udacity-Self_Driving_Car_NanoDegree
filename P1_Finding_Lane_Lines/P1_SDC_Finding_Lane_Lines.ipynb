{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** \n",
    "---\n",
    "This is the first project in Udacity's Self Driving Car Nanodegree Program. \n",
    "\n",
    "The aim of this project is to detect road lane lines captured by camera mounted on a car dashboard. \n",
    "  \n",
    "This project involves \n",
    "*  lane detection using color selection,   \n",
    "*  region of interest selection,   \n",
    "*  grayscaling,   \n",
    "*  Gaussian smoothing,   \n",
    "*  Canny Edge Detection and  \n",
    "*  Hough Tranform line detection. \n",
    "\n",
    "The static image output should look like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='line-segments-example.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='laneLines_thirdPass.jpg'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td align=\"center\">\n",
    "        Image on lane detection\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "        Image on connect/average/extrapolate lane segements\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Detect left and right lane \n",
    "\n",
    "def detect_lanes_average_extrapolate(lines):\n",
    "    \"\"\"\n",
    "    `lines` are the list of Hough lines.\n",
    "        \n",
    "    Returns List of end points and slope for left and right lane.\n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    left_lane = []\n",
    "    right_lane = []    \n",
    "\n",
    "    for line in lines:\n",
    "        for xi,yi,xj,yj in line:\n",
    "            slope = 1.0*(yj-yi)/(xj-xi)\n",
    "            \n",
    "            if(slope > slope_threshold_lower and slope < slope_threshold_higher):\n",
    "                left_lane.append([xi, yi, xj, yj, slope])\n",
    "            elif(slope < -slope_threshold_lower and slope > -slope_threshold_higher):\n",
    "                right_lane.append([xi, yi, xj, yj, slope])\n",
    "\n",
    "    # Calculate average of x1, x2, y1, y2, slope\n",
    "    mean_left_lane = np.mean(left_lane, axis = 0)\n",
    "    mean_right_lane = np.mean(right_lane, axis = 0)\n",
    "    \n",
    "    # Calculate average x and y for left and right lanes\n",
    "    mean_left_point = [np.mean([mean_left_lane[0], mean_left_lane[2]]), \\\n",
    "                                np.mean([mean_left_lane[1], mean_left_lane[3]])]\n",
    "                                        \n",
    "    mean_right_point = [np.mean([mean_right_lane[0], mean_right_lane[2]]), \\\n",
    "                                np.mean([mean_right_lane[1], mean_right_lane[3]])]\n",
    "                                       \n",
    "    # Calculate intercept: c = y - m*x\n",
    "    left_line_intercept = mean_left_point[1] - mean_left_lane[4]*mean_left_point[0]  \n",
    "    right_line_intercept = mean_right_point[1] - mean_right_lane[4]*mean_right_point[0]  \n",
    "\n",
    "    # Calculate end points of lanes                            \n",
    "    left_lane_SW_point = [ np.round((y1-left_line_intercept)/mean_left_lane[4]), y1]\n",
    "    left_lane_NW_point = [ np.round((y2-left_line_intercept)/mean_left_lane[4]), y2]\n",
    "\n",
    "    right_lane_SE_point = [ np.round((y1-right_line_intercept)/mean_right_lane[4]), y1]\n",
    "    right_lane_NE_point = [ np.round((y2-right_line_intercept)/mean_right_lane[4]), y2]\n",
    "\n",
    "    # List of end points and slope for left and right lane: \n",
    "        # xl1, yl1, xl2, yl2, slopel, xr1, yr1, xr2, yr2, sloper\n",
    "    detected_lane_endpoints_slope = [int(round(left_lane_SW_point[0])), \\\n",
    "                                     int(round(left_lane_SW_point[1])), \\\n",
    "                                     int(round(left_lane_NW_point[0])), \\\n",
    "                                     int(round(left_lane_NW_point[1])), \\\n",
    "                                     mean_left_lane[4] ,\\\n",
    "                                     int(round(right_lane_SE_point[0])), \\\n",
    "                                     int(round(right_lane_SE_point[1])), \\\n",
    "                                     int(round(right_lane_NE_point[0])), \\\n",
    "                                     int(round(right_lane_NE_point[1])), \\\n",
    "                                     mean_right_lane[4] ]\n",
    "\n",
    "    return detected_lane_endpoints_slope   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw lanes on image\n",
    "\n",
    "def drawlanes(image, lane, color=[255, 0, 0], thickness=4):\n",
    "    \"\"\"\n",
    "    `image` is the original image.\n",
    "    `lane` is the list of end points and slope for left and right lane\n",
    "        \n",
    "    Returns image with lanes.\n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    line_img = np.zeros((*image.shape, 3), dtype=np.uint8)\n",
    "\n",
    "    lx1,ly1,lx2,ly2,lslope,rx1,ry1,rx2,ry2,rslope = lane\n",
    "    cv2.line(line_img, (lx1, ly1), (lx2, ly2), color, thickness)\n",
    "    cv2.line(line_img, (rx1, ry1), (rx2, ry2), color, thickness)\n",
    "            \n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lane detection pipeline \n",
    "\n",
    "def lanedetection_pipeline(image):\n",
    "    \"\"\"\n",
    "    `image` is the original image\n",
    "        \n",
    "    Returns detected lanes image and list of end points and slope for left and right lane.\n",
    "    \"\"\"        \n",
    "    gray = grayscale(image)\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "    cannyedges = canny(blur_gray, low_threshold, high_threshold)\n",
    "    masked_edges = region_of_interest(cannyedges, vertices)\n",
    "    houghlines, lines = hough_lines(masked_edges, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    lane = detect_lanes_average_extrapolate(lines) \n",
    "    detected_lanes = drawlanes(masked_edges, lane, color=[255, 0, 0], thickness=6) \n",
    "    \n",
    "    return detected_lanes, lane     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants Deceleration   \n",
    "\n",
    "kernel_size = 5        # Gaussian blur kernel size\n",
    "low_threshold = 50     # Canny Edge detection parameter\n",
    "high_threshold = 150   # Canny Edge detection parameter\n",
    "\n",
    "#### Define masking polygon\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "imshape = image.shape\n",
    "\n",
    "# Points defining polygon mask\n",
    "x1, y1 = 120, imshape[0]\n",
    "x4, y4 = 920, y1\n",
    "x2, y2 = 435, 325\n",
    "x3, y3 = ((x1+x4) - x2)- 50, y2\n",
    "vertices = np.array([[(x1,y1),(x2, y2), (x3, y3), (x4,y4)]], dtype=np.int32)\n",
    "\n",
    "# Define the Hough transform parameters\n",
    "rho = 1 # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "threshold = 20  #20   # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_len = 50 # 50 #minimum number of pixels making up a line\n",
    "max_line_gap = 30    # maximum gap in pixels between connectable line segments\n",
    "\n",
    "# Define slope threshold to detect only the lanes\n",
    "slope_threshold_lower = 0.46 # to select only lanes \n",
    "slope_threshold_higher = 0.83 # higher angle of lanes\n",
    "\n",
    "# smoothing parameter for lanes across video frames\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Images\n",
    "\n",
    "The code is first tested on sample images. The results are saved in the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1f18539c1adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdetected_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanedetection_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mroad_with_lane_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetected_lanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mα\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mβ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mλ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bfe1a09846f3>\u001b[0m in \u001b[0;36mlanedetection_pipeline\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcannyedges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmasked_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcannyedges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhoughlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhough_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_line_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_line_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_lanes_average_extrapolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdetected_lanes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrawlanes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlane\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "imagelist = [\"test_images/\"+imgname for imgname in os.listdir(\"test_images/\")]\n",
    "\n",
    "for image in imagelist:\n",
    "\n",
    "    image_original = mpimg.imread(image)\n",
    "    img = (np.copy(image_original)*255).astype('uint8')\n",
    "    \n",
    "    detected_lanes, _ = lanedetection_pipeline(img)\n",
    "    road_with_lane_edges = weighted_img(detected_lanes, mpimg.imread(image), α=0.8, β=1., λ=0.)\n",
    "    \n",
    "    mpimg.imsave(\"test_images/\"+image.replace(\"test_images/\",\"\")+\"-after.png\", road_with_lane_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='test_images/solidWhiteCurve.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='test_images/solidWhiteCurve-after.png'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='test_images/solidWhiteRight.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='test_images/solidWhiteRight-after.png'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='test_images/solidYellowCurve.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='test_images/solidYellowCurve-after.png'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='test_images/solidYellowCurve2.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='test_images/solidYellowCurve2-after.png'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='test_images/solidWhiteCurve.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='test_images/solidWhiteCurve-after.png'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='test_images/solidYellowLeft.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='test_images/solidYellowLeft-after.png'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>\n",
    "        <img src='test_images/whiteCarLaneSwitch.jpg'>\n",
    "    </td>\n",
    "    <td>\n",
    "        <img src='test_images/whiteCarLaneSwitch-after.png'>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td align=\"center\">\n",
    "        Original image\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "        Image with detected lanes\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "Now let's extend the image pipeline to videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Video Analysis\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    `image` is an handle to image \n",
    "    \"\"\"     \n",
    "    \n",
    "    global cache_lane\n",
    "    img = (np.copy(image)*255).astype('uint8')\n",
    "    line_img = np.zeros([image.shape[0], image.shape[1]], dtype=np.uint8)\n",
    "   \n",
    "    _, predicted_lane = lanedetection_pipeline(img)\n",
    "    \n",
    "    smooth_lane_0 = alpha* np.asarray(predicted_lane) + (1-alpha)* np.asarray(cache_lane) \n",
    "    \n",
    "    smooth_lane = [int(round(smooth_lane_0[0])), int(round(smooth_lane_0[1])), \\\n",
    "                int(round(smooth_lane_0[2])), int(round(smooth_lane_0[3])), smooth_lane_0[4] ,\\\n",
    "                int(round(smooth_lane_0[5])), int(round(smooth_lane_0[6])), \\\n",
    "                int(round(smooth_lane_0[7])), int(round(smooth_lane_0[8])), smooth_lane_0[9] ]\n",
    "    \n",
    "    detected_lanes = drawlanes(line_img, smooth_lane,color=[255, 0, 0], thickness=4)\n",
    "    road_with_lane_edges = weighted_img(detected_lanes, image, α=0.8, β=1., λ=0.)\n",
    "    cache_lane = smooth_lane\n",
    "    \n",
    "    return road_with_lane_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cache_lane initialization for lane smoothing in videos\n",
    "\n",
    "def cache_lane_initialization(clip):\n",
    "    \"\"\"\n",
    "    `clip` is an handle to video clip \n",
    "    \"\"\" \n",
    "    global cache_lane\n",
    "    \n",
    "    cache_lane = [] \n",
    "    frame_t0 = clip.get_frame(t=0)\n",
    "    img = (np.copy(frame_t0)*255).astype('uint8')\n",
    "    _, cache_lane = lanedetection_pipeline(img)\n",
    "    \n",
    "    return cache_lane  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1: **\n",
    "Video with solid white lane on the right first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-8c1a62510c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclip1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"solidWhiteRight.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcache_lane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_lane_initialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mwhite_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time white_clip.write_videofile(white_output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-52efbbeeafc3>\u001b[0m in \u001b[0;36mcache_lane_initialization\u001b[0;34m(clip)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mframe_t0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_t0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_lane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanedetection_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcache_lane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bfe1a09846f3>\u001b[0m in \u001b[0;36mlanedetection_pipeline\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcannyedges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur_gray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmasked_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcannyedges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mhoughlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhough_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_line_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_line_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mlane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_lanes_average_extrapolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdetected_lanes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrawlanes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlane\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\") # Input\n",
    "white_output = 'white.mp4' # Output\n",
    "\n",
    "cache_lane = cache_lane_initialization(clip1)\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video width=\"800\" height=\"450\" controls>\n",
    "  <source src=\"white.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2: **\n",
    "Video with solid yellow lane on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip2 = VideoFileClip('solidYellowLeft.mp4') # Input\n",
    "yellow_output = 'yellow.mp4' # Output\n",
    "\n",
    "cache_lane = cache_lane_initialization(clip2)\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<video width=\"800\" height=\"450\" controls>\n",
    "  <source src=\"yellow.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "The project was particularly challanging for \n",
    "Congratulations on finding the lane lines!  As the final step in this project, we would like you to share your thoughts on your lane finding pipeline... specifically, how could you imagine making your algorithm better / more robust?  Where will your current algorithm be likely to fail?\n",
    "\n",
    "Please add your thoughts below,  and if you're up for making your pipeline more robust, be sure to scroll down and check out the optional challenge video below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clip3 = VideoFileClip('challenge.mp4') # Input\n",
    "challenge_output = 'extra.mp4' # Output\n",
    "\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<video width=\"800\" height=\"450\" controls>\n",
    "  <source src=\"extra.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
